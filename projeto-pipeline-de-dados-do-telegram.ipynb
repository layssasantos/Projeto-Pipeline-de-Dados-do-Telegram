{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "175882c5",
   "metadata": {
    "id": "nlvFtYHQy_5L",
    "papermill": {
     "duration": 0.021314,
     "end_time": "2024-01-22T18:54:38.401409",
     "exception": false,
     "start_time": "2024-01-22T18:54:38.380095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Projeto Pipeline de Dados do Telegram**\n",
    "**por [Layssa Santos](https://www.linkedin.com/in/layssa-santos/)**\n",
    "\n",
    "![projeto](https://raw.githubusercontent.com/layssasantos/Projeto-Pipeline-de-Dados-do-Telegram/a30172f0845ebe586018bc4990305927977db073/Imagens/Projeto.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab4cea7",
   "metadata": {
    "id": "InBKaJF_8HP1",
    "papermill": {
     "duration": 0.02036,
     "end_time": "2024-01-22T18:54:38.443080",
     "exception": false,
     "start_time": "2024-01-22T18:54:38.422720",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1R_LhA6ivl4D_S6U40gXeKqZpOtRLQJ65?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc54bef",
   "metadata": {
    "id": "WS2uyce1WoVz",
    "papermill": {
     "duration": 0.0211,
     "end_time": "2024-01-22T18:54:38.485802",
     "exception": false,
     "start_time": "2024-01-22T18:54:38.464702",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## **Tópicos**\n",
    "#### 1. [**Contexto**](#contexto)  \n",
    "    1.1 Chatbot  \n",
    "#### 2. [**Arquitetura**](#arqui)  \n",
    "#### 3. [**Sistema Transacional**](#trans)\n",
    "    3.1 Telegram\n",
    "    3.3 Dados Transacionais\n",
    "#### 4. [**Sistema Analítico**](#analitico)    \n",
    "    4.1 Ingestão\n",
    "    4.2 ETL\n",
    "    4.3 Apresentação\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b416f17",
   "metadata": {
    "id": "8wD750LAqnFW",
    "papermill": {
     "duration": 0.021201,
     "end_time": "2024-01-22T18:54:38.529215",
     "exception": false,
     "start_time": "2024-01-22T18:54:38.508014",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id='contexto'></a>\n",
    "## 1\\. **Contexto**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c96f22",
   "metadata": {
    "id": "qGKk2MWRXhOr",
    "papermill": {
     "duration": 0.021043,
     "end_time": "2024-01-22T18:54:38.571086",
     "exception": false,
     "start_time": "2024-01-22T18:54:38.550043",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Este projeto consiste em relacionar o mundo de chatbots em aplicativos como o Telegram com a computação em nuvem da Amazon Web Services (AWS). O pipeline de dados se inicia com a captura dos dados fornecidos pelo bot do Telegram via API WEB, pelo AWS API Gateway. Adiante, na plataforma da AWS, são realizadas as três etapas: ingestão, ETL e apresentação dos dados, utilizando-se ferramentas como AWS Lambda, AWS S3, AWS Event Bridge e AWS Athena durante o processo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac2818d",
   "metadata": {
    "id": "Ay4UkojwGskg",
    "papermill": {
     "duration": 0.020608,
     "end_time": "2024-01-22T18:54:38.613096",
     "exception": false,
     "start_time": "2024-01-22T18:54:38.592488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1.1. Chatbot**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef1c238",
   "metadata": {
    "id": "JUonSt7kxZyj",
    "papermill": {
     "duration": 0.020371,
     "end_time": "2024-01-22T18:54:38.654116",
     "exception": false,
     "start_time": "2024-01-22T18:54:38.633745",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Um **chatbot** é um tipo de software que interage com usuários através de conversas automatizadas em plataformas de mensagens. Ele está cada vez mais presente em aplicativos e sites e é capaz de compreender e interpretar a intenção do usuário por meio de texto ou voz, fornecendo respostas relevantes e precisas em tempo real.\n",
    "\n",
    "Uma aplicação comum de **chatbots** é o seu uso no atendimento ao cliente, onde, de maneira geral, ajudam clientes a resolver problemas ou esclarecer dúvidas recorrentes antes mesmo que um atendente humano seja acionado.\n",
    "\n",
    "![](https://github.com/layssasantos/Projeto-Pipeline-de-Dados-do-Telegram/blob/main/Imagens/chatbot.jpg?raw=true)\n",
    "\n",
    "Nesse sentido, chatbots podem funcionar como uma boa fonte de `dados transacionais`, pois também são capazes de fornecer informações específicas e detalhadas que registram atividades individuais ou transações dentro de um sistema ou organização.\n",
    "\n",
    "Assim, torna-se útil armazenar mensagens desses chats em base de dados para serem analisadas, sendo possível saber, por exemplo, quais mensagens ou dúvidas são mais frequentes, quais respostas são mais esperadas, qual a média de tamanho das mensagens, quais usuários costumam mandar mais mensagens, em quais grupos, e assim por diante.\n",
    "\n",
    "Em geral, as mensagens captadas pelo chatbot são fornecidas por API's para uso externo, e apresentam formatos de dados semi-estruturados, como JSON. Deste modo, para a tranformação em `dados analíticos`, muitas vezes é necessário realizar um data wrangling dos dados transicionais para que se tornem analisáveis por profissionais de dados. Isto pode ser feito por uma arquitetura em nuvem, como na AWS (Amazon Web Services), que também nos permite realizar consultas SQL ao fim do processo. É o que veremos ao longo deste projeto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4a71b0",
   "metadata": {
    "id": "-ndPsk2mWENR",
    "papermill": {
     "duration": 0.020739,
     "end_time": "2024-01-22T18:54:38.695465",
     "exception": false,
     "start_time": "2024-01-22T18:54:38.674726",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91f2e95",
   "metadata": {
    "id": "qIQ6SwBScdJ5",
    "papermill": {
     "duration": 0.020472,
     "end_time": "2024-01-22T18:54:38.737473",
     "exception": false,
     "start_time": "2024-01-22T18:54:38.717001",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id='arqui'></a>\n",
    "## **2\\. Arquitetura**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c919fa",
   "metadata": {
    "id": "BRDXe_3kq-5f",
    "papermill": {
     "duration": 0.020546,
     "end_time": "2024-01-22T18:54:38.778889",
     "exception": false,
     "start_time": "2024-01-22T18:54:38.758343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Conforme exemplifica o diagrama a seguir, a arquitetura deste projeto é divido em dois sistemas: o **sistema transacional**, onde os dados são produzidos, e o **sistema analítico**, na Amazon Web Services (AWS), onde os dados são analisados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6e21bc",
   "metadata": {
    "id": "hXiltNloMSqe",
    "papermill": {
     "duration": 0.020838,
     "end_time": "2024-01-22T18:54:38.884470",
     "exception": false,
     "start_time": "2024-01-22T18:54:38.863632",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![arquitetura](https://raw.githubusercontent.com/layssasantos/Projeto-Pipeline-de-Dados-do-Telegram/76120fea0d0cb0764eeaa3ae632bb24d4dbd6591/Imagens/arquitetura-pipeline.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca70d77",
   "metadata": {
    "id": "iuLq-jahxQwK",
    "papermill": {
     "duration": 0.020501,
     "end_time": "2024-01-22T18:54:38.926446",
     "exception": false,
     "start_time": "2024-01-22T18:54:38.905945",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " - **Telegram**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f230734b",
   "metadata": {
    "id": "jGybyfvUxVfu",
    "papermill": {
     "duration": 0.02046,
     "end_time": "2024-01-22T18:54:38.967749",
     "exception": false,
     "start_time": "2024-01-22T18:54:38.947289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "O `Telegram` representa a fonte de dados transacionais. Mensagens enviadas por usuários em um grupo são capturadas por um *bot* e redirecionadas via *webhook* do *backend* do aplicativo para um *endpoint* (endereço *web* que aceita requisições HTTP) exposto pelo `AWS API Gateway`. As mensagens trafegam no corpo ou *payload* da requisição."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d8bfac",
   "metadata": {
    "id": "9-fBfUagxYAy",
    "papermill": {
     "duration": 0.020594,
     "end_time": "2024-01-22T18:54:39.009288",
     "exception": false,
     "start_time": "2024-01-22T18:54:38.988694",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " - **AWS | Ingestão**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890641b0",
   "metadata": {
    "id": "GM7BSNTJxYA1",
    "papermill": {
     "duration": 0.020644,
     "end_time": "2024-01-22T18:54:39.051398",
     "exception": false,
     "start_time": "2024-01-22T18:54:39.030754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Uma requisição HTTP com o conteúdo da mensagem em seu *payload* é recebida pelo `AWS API Gateway` que, por sua vez, as redireciona para o `AWS Lambda`, servindo assim como seu gatilho. Já o `AWS Lambda` recebe o *payload* da requisição em seu parâmetro *event*, salva o conteúdo em um arquivo no formato JSON (original, mesmo que o *payload*) e o armazena no `AWS S3` particionado por dia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462a437c",
   "metadata": {
    "id": "aHLNPrdb002s",
    "papermill": {
     "duration": 0.021374,
     "end_time": "2024-01-22T18:54:39.093877",
     "exception": false,
     "start_time": "2024-01-22T18:54:39.072503",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " - **AWS | ETL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1b73d1",
   "metadata": {
    "id": "lmBTC8an002u",
    "papermill": {
     "duration": 0.021629,
     "end_time": "2024-01-22T18:54:39.136751",
     "exception": false,
     "start_time": "2024-01-22T18:54:39.115122",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Uma vez ao dia, o `AWS Event Bridge` aciona o `AWS Lambda` que processa todas as mensagens do dia anterior (atraso de um dia ou D-1), denormaliza o dado semi-estruturado típico de arquivos no formato JSON, salva o conteúdo processado em um arquivo no formato Apache Parquet e o armazena no `AWS S3` particionado por dia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75de7efa",
   "metadata": {
    "id": "wTcGZ8vu01HQ",
    "papermill": {
     "duration": 0.020733,
     "end_time": "2024-01-22T18:54:39.178634",
     "exception": false,
     "start_time": "2024-01-22T18:54:39.157901",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " - **AWS | Apresentação**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48acb39",
   "metadata": {
    "id": "1yOL03yk01HR",
    "papermill": {
     "duration": 0.020586,
     "end_time": "2024-01-22T18:54:39.220166",
     "exception": false,
     "start_time": "2024-01-22T18:54:39.199580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Por fim, uma tabela do `AWS Athena` é apontada para o *bucket* do `AWS S3` que armazena o dado processado: denormalizado, particionado e orientado a coluna. Profissionais de dados podem então executar consultas analíticas (agregações, ordenações, etc.) na tabela utilizando o SQL para a extração de *insights*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807a9af9",
   "metadata": {
    "id": "OepGbWJya2cF",
    "papermill": {
     "duration": 0.020675,
     "end_time": "2024-01-22T18:54:39.262683",
     "exception": false,
     "start_time": "2024-01-22T18:54:39.242008",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b03a889",
   "metadata": {
    "id": "eG0kMc3Ct4Hf",
    "papermill": {
     "duration": 0.020648,
     "end_time": "2024-01-22T18:54:39.304244",
     "exception": false,
     "start_time": "2024-01-22T18:54:39.283596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id='trans'></a>\n",
    "### **3. Sistema Transacional**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c9c481",
   "metadata": {
    "id": "pM7hqL28wjl-",
    "papermill": {
     "duration": 0.02081,
     "end_time": "2024-01-22T18:54:39.346048",
     "exception": false,
     "start_time": "2024-01-22T18:54:39.325238",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Um sistema transacional é uma estrutura tecnológica e de dados que suporta as transações diárias de uma fonte de dados. Ele é responsável por coletar, registrar e transmitir dados para uma cadeia de processos que tratarão os dados para posterior análise. Em resumo, os sistemas transacionais são projetados para ingerir dados criados diariamente e salvá-los em um banco de dados ou DataLake. [Fonte](https://insightsoftware.com/encyclopedia/transactional-systems/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f02eba",
   "metadata": {
    "id": "hC_nA5qZxkCl",
    "papermill": {
     "duration": 0.020535,
     "end_time": "2024-01-22T18:54:39.387616",
     "exception": false,
     "start_time": "2024-01-22T18:54:39.367081",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **3.1. Telegram**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745165c4",
   "metadata": {
    "id": "OHJKzuHlxYmn",
    "papermill": {
     "duration": 0.020598,
     "end_time": "2024-01-22T18:54:39.429043",
     "exception": false,
     "start_time": "2024-01-22T18:54:39.408445",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "O Telegram representa a fonte de dados transacionais. Mensagens enviadas por usuários em um grupo são capturadas por um bot e redirecionadas via webhook do backend do aplicativo para um endpoint (endereço web que aceita requisições HTTP) exposto pelo AWS API Gateway. As mensagens trafegam no corpo ou payload da requisição."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8c7758",
   "metadata": {
    "id": "AQ2JD_pz5zhf",
    "papermill": {
     "duration": 0.020573,
     "end_time": "2024-01-22T18:54:39.470623",
     "exception": false,
     "start_time": "2024-01-22T18:54:39.450050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> **Criação do bot**:\n",
    "Na plataforma web do Telegram foi criado um bot a partir do Botfather e dado o nome de\n",
    "m42_project_layssa_bot\n",
    "\n",
    "![criarbot](https://github.com/layssasantos/Projeto-Pipeline-de-Dados-do-Telegram/blob/main/Imagens/create_bot.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cdf205",
   "metadata": {
    "id": "et80Wgvx6Cg-",
    "papermill": {
     "duration": 0.02164,
     "end_time": "2024-01-22T18:54:39.513169",
     "exception": false,
     "start_time": "2024-01-22T18:54:39.491529",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    ">Após a criação do bot, criei um grupo ao qual tenho interesse em captar as interações entre os integrantes.\n",
    "\n",
    "![](https://github.com/layssasantos/Projeto-Pipeline-de-Dados-do-Telegram/blob/main/Imagens/group_telegram.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6082cdaa",
   "metadata": {
    "id": "T4RNFWDl6Pve",
    "papermill": {
     "duration": 0.020532,
     "end_time": "2024-01-22T18:54:39.554565",
     "exception": false,
     "start_time": "2024-01-22T18:54:39.534033",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    ">O bot criado foi adicionado ao grupo e encarregado a  administrador, permitindo assim que ele capte a conversa de todos os integrantes do grupo.\n",
    "\n",
    "![](https://github.com/layssasantos/Projeto-Pipeline-de-Dados-do-Telegram/blob/main/Imagens/group_bot_adm.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d84d7e",
   "metadata": {
    "id": "-Cn4jTLV16ln",
    "papermill": {
     "duration": 0.020478,
     "end_time": "2024-01-22T18:54:39.595876",
     "exception": false,
     "start_time": "2024-01-22T18:54:39.575398",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As mensagens captadas pelo bot podem ser acessadas via API.\n",
    "\n",
    "> 💡 API é a sigla para \"Application Programming Interface\", que em português significa \"Interface de Programação de Aplicações\", ela atua como uma interface intermediária que permite a comunicação e a interação entre diferentes sistemas, aplicativos ou plataformas, facilitando o compartilhamento de informações e funcionalidades de maneira eficiente e padronizada.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabce771",
   "metadata": {
    "id": "J010qHE534Wn",
    "papermill": {
     "duration": 0.020502,
     "end_time": "2024-01-22T18:54:39.637244",
     "exception": false,
     "start_time": "2024-01-22T18:54:39.616742",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3.2. **Dados Transacionais**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fac8e5",
   "metadata": {
    "id": "u4gup5Gy4gzl",
    "papermill": {
     "duration": 0.020945,
     "end_time": "2024-01-22T18:54:39.679172",
     "exception": false,
     "start_time": "2024-01-22T18:54:39.658227",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Para explorarmos os dados transacionais fornecidos pelo API de Bot do Telegram, utilizaremos o token de acesso fornecido pelo BotFather na criação do bot e com o auxílio do pacote nativo do Python getpass vamos garantir a privacidade da informação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06512fd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T18:54:39.723537Z",
     "iopub.status.busy": "2024-01-22T18:54:39.722957Z",
     "iopub.status.idle": "2024-01-22T18:54:40.254123Z",
     "shell.execute_reply": "2024-01-22T18:54:40.252493Z"
    },
    "id": "tz6y8ROkV92M",
    "outputId": "19f9483e-f3f0-4711-8a81-aa2acb728dc9",
    "papermill": {
     "duration": 0.556105,
     "end_time": "2024-01-22T18:54:40.256476",
     "exception": true,
     "start_time": "2024-01-22T18:54:39.700371",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "StdinNotImplementedError",
     "evalue": "getpass was called, but this frontend does not support input requests.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStdinNotImplementedError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgetpass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m getpass\n\u001b[0;32m----> 3\u001b[0m token \u001b[38;5;241m=\u001b[39m \u001b[43mgetpass\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py:1176\u001b[0m, in \u001b[0;36mKernel.getpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1175\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetpass was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1178\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n",
      "\u001b[0;31mStdinNotImplementedError\u001b[0m: getpass was called, but this frontend does not support input requests."
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "token = getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0d263a",
   "metadata": {
    "id": "3CUofqbwV92N",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "A `url` base é comum a todos os métodos da API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918a68e0",
   "metadata": {
    "id": "SSNVqUZEV92N",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "base_url = f'https://api.telegram.org/bot{token}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814b5997",
   "metadata": {
    "id": "QvHUmCcAFmKY",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "- **getMe**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d196f463",
   "metadata": {
    "id": "O17cMTP1FmKY",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "O método `getMe` retorna informações sobre o *bot*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952adc09",
   "metadata": {
    "id": "Saxm4DICV92O",
    "outputId": "17c4a893-d6c7-4189-e7da-d9e29b5a2e00",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(url=f'{base_url}/getMe')\n",
    "\n",
    "print(json.dumps(json.loads(response.text), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6924e82",
   "metadata": {
    "id": "34uFkaArFmKZ",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    " - **getUpdates**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b741d044",
   "metadata": {
    "id": "tkKNp0UwFmKa",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "O método `getMe` retorna as mensagens captadas pelo *bot*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191590b3",
   "metadata": {
    "id": "M9ZfS-RNV92Q",
    "outputId": "afd30e42-6c2f-4412-d13f-7dd20f1e1505",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = requests.get(url=f'{base_url}/getUpdates')\n",
    "\n",
    "print(json.dumps(json.loads(response.text), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279eef3f",
   "metadata": {
    "id": "Q8-shrCz4KyX",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    " - **Descrição:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab10ffd",
   "metadata": {
    "id": "d6uhrv3K1JXc",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "| chave | tipo valor | opcional | descrição |\n",
    "| -- | -- | -- | -- |\n",
    "| updated_id | int | não | id da mensagem enviada ao **bot** |\n",
    "| message_id | int | não | id da mensagem enviada ao grupo |\n",
    "| from_id | int | sim | id do usuário que enviou a mensagem |\n",
    "| from_is_bot | bool | sim | se o usuário que enviou a mensagem é um **bot** |\n",
    "| from_first_name | str | sim | primeiro nome do usário que enviou a mensagem |\n",
    "| chat_id | int | não | id do *chat* em que a mensagem foi enviada |\n",
    "| chat_type | str | não | tipo do *chat*: private, group, supergroup ou channel |\n",
    "| date | int | não | data de envio da mensagem no formato unix |\n",
    "| text | str | sim | texto da mensagem |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0de88c",
   "metadata": {
    "id": "PFbBLa5AeoOE",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Uma mensagem recuperada via API é um dado semi-estruturado no formato JSON com algumas chaves mandatórias e diversas chaves opcionais, estas últimas presentes (ou não) dependendo do tipo da mensagem. Por exemplo, mensagens de texto apresentam a chave `text` enquanto mensagens de áudio apresentam a chave `audio`. Neste projeto vamos focar em mensagens do tipo texto, ou seja, vamos ingerir as chaves mandatórias e a chave `text`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a6d404",
   "metadata": {
    "id": "vTrCkLt3GvVk",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d37fea",
   "metadata": {
    "id": "hk4YzInlAefV",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<a id='analitico'></a>\n",
    "### **4. Sistema Analítico**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1522b1a",
   "metadata": {
    "id": "Vmj1l2vTCDC9",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Esses sistemas apoiam a tomada de decisões, relatórios, consultas e análises. São projetados para lidar com consultas complexas em grandes volumes de dados vindos dos sistemas transacionais, organizam esses dados e os processam de maneira a criar insights úteis. Neste projeto o sistema compreende a retirada dos dados brutos (raw) do datalake, a transformação deles em informação e a análise em busca de padrões e insights. [Fonte](http://bi-insider.com/posts/types-of-enterprise-data-transactional-analytical-master/)\n",
    "\n",
    "Neste projeto, o sistema analítico irá compreender a Ingestão, ETL e Apresentação dos dados fornecidos via API *Web* de bots do Telegram, tudo isso na Amazon Web Services."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28acf07",
   "metadata": {
    "id": "a3jThgmVV91_",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### **4.1\\. Ingestão**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f164152",
   "metadata": {
    "id": "KxMY-mKLV92D",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "A etapa de **ingestão** é responsável, como seu o próprio nome diz, pela ingestão dos dados transacionais em ambientes analíticos. De maneira geral, o dado ingerido é persistido no formato mais próximo do original, ou seja, nenhuma transformação é realizada em seu conteúdo ou estrutura (*schema*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec047fc8",
   "metadata": {
    "id": "JJKKD2FNaVnW",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Sendo assim, precisamos de um serviço da AWS que forneça um API *web* para receber os dados redirecionados, o `AWS API Gateway` (documentação neste [link](https://docs.aws.amazon.com/pt_br/apigateway/latest/developerguide/welcome.html)). Dentre suas diversas funcionalidades, o `AWS API Gateway` permite o redirecionamento do dado recebido para outros serviços da AWS. Logo, vamos conecta-lo ao `AWS Lambda`, que pode sua vez, irá armazenar o dado em seu formato original (JSON) em um *bucket* do `AWS S3`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b15d10c",
   "metadata": {
    "id": "BVx3Ii0DFwCa",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "- **AWS API GATEWAY**\n",
    "\n",
    "> [![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAH0AAAB9CAMAAAC4XpwXAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAA2UExURecVe+tBlOkkg+1PnPvT5v////3w9+oyi/zi7/BtrO9epPnF3vanzfWZxfOKvfF7tfe21gAAAHixfmsAAAASdFJOU///////////////////////AOK/vxIAAAAJcEhZcwAAFxEAABcRAcom8z8AAAPISURBVGhD7ZrblqsgEETVeIkxOvn/r52qBpRcRBTwTNZhvwBGKaobkHFNkclkMplMJvOfUurSSeV1127Ka9N2ur5O1TZ1r+vxgDa46dY6JW+7xtVX2j7qN3VjRP9G21O9lVsj+dfaQ4fyoq+tA/W6u8sTEfzP2kUxNM12fxe4LopulKcC9S3tovDy3uNuluH+jbZewfC+nXflnYTpP/kmXt6Rd/FODutXb9q78m44pP9Je2feDfv1X/Jt2Jl3g9a/bo9ckM3yxTfZnXeD1n/r8CNUf9c+lHeD6Pu9/D53cDDvBq+HCbx/VIf37Q4w9FpXn4B6sPftyHOf19Unvt+7V97DvK+p+875NN7rphkv/YUWShTsjE2szUqX3aWfEuZd0FXew+Ydqix/ZNwgTeTRgYAq1bmseYiy1JF0kCbykKyH68DfRpRUZ3NE5FliTpR1DZU0kUfetztIOeu8zrRp8h7qPTjy2+vdsdsER/4E70F5Txn57Q4cs+6EOZ8y8id43zXnq2Z4Csi53l/faSl3G2NzsYv3zISiMlcc3oMjr4c/zedWiDUVykeDlw1J7x3RFsPg0TQPFPxzXck7vMfJO8VrGgYIPK9V+E3Jp57zIq6uyHFCxjHLJ/ZO8UE754FD55u/sp5yr+vFrQm7nKhMn9p9sHfnnIfE8uPzYuchL915Huo3OU/OO55e7IoerbZzeA+OPIYPdSOPG5cvtz+4jlbwenfP+YoBVvJ6sQviHO6C8+72rg7vIo/S9MjJKHFIO+cJ3WPXw5xrpa3Fpfdg75v7PNy3qKGNv1+EZQak9G7eZFdUMMilw1I5T/uWsTtA4Oc5t5ByzhvvBNm3mxpH3qNFHsCkmXM2KSNvqZd3/u38RsrIP3cw73MWDvWYkV/BkfeYkV8h2LvnnP9MSu/bHZw051dweA+O/F/3/mfVv3zOTyVAlQWP1bpplTjehXl3qAuo8mRLETax2+MJOWkg7CDMuyPyAqqf1HHqiqHu8N4SVB8oKMIm1EsU8o0aRcLIbw8fDyeL/L9d70HegyN/gvdU+/wJ3oNnXVDeU0Y+yLt35FvzbcQmxHuHbcg78k0zTG8DOOy9muDcV73ireB1AMe8VxOeIx7/oCZ0/BAhDOZ7GDnivef7SHqaPMVJOc0DUF8MwG7vxjWk/WacxTKAh/pIsM97X+vHr/ulFdYAEAEvdeW9l2kG2j0Bf8caACpe3luT63Y86NqmHM0A/PKuaMcg1zYXPQAv7yCKaxsOwGfJQvoezbVN6dVrZNeZTCaTyWQyX0JR/AIqIiw0xLKKOQAAAABJRU5ErkJggg==)](https://aws.amazon.com/pt/api-gateway/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0798f12d",
   "metadata": {
    "id": "wkOlO04qQVOT",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Na etapa de **ingestão**, o `AWS API Gateway` tem a função de receber as mensagens captadas pelo *bot* do **Telegram**, enviadas via *webhook*, e iniciar uma função do `AWS Lambda`, passando o conteúdo da mensagem no seu parâmetro *event*. Para tanto vamos criar uma API e configurá-la como gatilho da função do `AWS Lambda`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1659d2",
   "metadata": {
    "id": "kL6_P-YF6fT2",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    ">Criação da API com protocolo REST e método POST, configurado com integração do tipo proxy com o serviço Lambda.\n",
    "\n",
    "![](https://github.com/layssasantos/Projeto-Pipeline-de-Dados-do-Telegram/blob/main/Imagens/aws_api_create.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1681967e",
   "metadata": {
    "id": "X1keBevn6tPt",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Por fim, vamos fazer a implantação da API e obter o seu endereço *web*.\n",
    "\n",
    "![](https://github.com/layssasantos/Projeto-Pipeline-de-Dados-do-Telegram/blob/main/Imagens/aws_api_url.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10730eee",
   "metadata": {
    "id": "sCZAILZokiwx",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "- **WEBHOOK**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426516c1",
   "metadata": {
    "id": "hfj9zCtpS_Zj",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "A Ingestão pode ser conduzida de duas formas:\n",
    "\n",
    " - **Batch**: blocos de dados são ingeridos em uma frequência bem definida, geralmente na escala de horas ou dias;\n",
    " - **Streaming**: dados são ingeridos conforme são produzidos e disponibilizados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62ee902",
   "metadata": {
    "id": "Y7CfG9TsUgll",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Como o **Telegram** retem mensagens por apenas 24h em seus servidores, a ingestão via **streaming** é a mais indicada para este projeto. Para que seja possível esse tipo de **ingestão** seja possível, vamos utilizar um *webhook* (gancho *web*), ou seja, vamos redirecionar as mensagens automaticamente para o AWS API Gateway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7fcba5",
   "metadata": {
    "id": "iT0lOp3f4AC-",
    "outputId": "31a65162-c951-4f6b-fb3d-a84639f2231a",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#adicionando o endereço WEB fornecido pelo AWS API Gateway em uma variável\n",
    "\n",
    "aws_api_gateway_url = getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98757c42",
   "metadata": {
    "id": "b_bTFFGdV92P",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "O método `setWebhook` configura o redirecionamento das mensagens captadas pelo *bot* para o endereço *web* do paramametro `url`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6869f3fa",
   "metadata": {
    "id": "dg4BCC44avB-",
    "outputId": "c75c4b0d-71cd-4ab7-eac5-66a02c34ee35",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = requests.get(url=f'{base_url}/setWebhook?url={aws_api_gateway_url}')\n",
    "\n",
    "print(json.dumps(json.loads(response.text), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c274c29",
   "metadata": {
    "id": "T7cjJ3tL3xDV",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Utilizando o método `getWebhookInfo` para obter as informações sobre o *webhook* configurado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a692027f",
   "metadata": {
    "id": "0D3O01qH3tVV",
    "outputId": "601ee345-9c9c-4335-b5fb-1e74b7fbb6b3",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = requests.get(url=f'{base_url}/getWebhookInfo')\n",
    "\n",
    "print(json.dumps(json.loads(response.text), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae639f05",
   "metadata": {
    "id": "8rg_hCCBXZfE",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "- **AWS S3**\n",
    "\n",
    "> [![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAH0AAAB9CAMAAAC4XpwXAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAA2UExURXqhFoKnJYutM5OzQqS+X7TKfMXWmd7nxebt0+7z4vf58P///9Xits3cqLzQiqzEbZu5UAAAAHp0R3IAAAASdFJOU///////////////////////AOK/vxIAAAAJcEhZcwAAFxEAABcRAcom8z8AAARXSURBVGhD7ZrrtqMgDIWLeMMq8v5POzsYqq1tNUnPr/GbWWdRVyFcskmg3i4uLi4uLi4u/nucqzxTOX725zhfN20XwnB/Zui7Ns7p7/rh6tjtrO7o2sZzhZ/h6jZw8yvDAn/a0sXf9cDFzZCHfmyb2Xu3nWT4QF3Hqdv2sP1FB5x/mB6m6Ct+/Ik0tx1//T60RjdwsbQ0zkeGV1IsPejOV9rh2mXYfZQ30nAHRq19n5dxmLT1m8UNWv4owrXZdsMfVaQ8d728+27Mtq3bR6LxD2L3p5F3v9i6yG8HYUM16lgFw3g0NXH5JBO8lYtmZgyeiyfBxJv8bUuFwXPxJFitwEUzaKvn4kkSOR2XjdSQnXAVyVXu/Q/cbtk2hDuOozp2t0eMyu3U/PksJbC1ljgRS8iVWke9aakbFDEGuNTlEQwN/khbwHLFEicwA7NoCZwvCckQHbkQPz8NrJOj1muuMMb6RBecb9q+LFuIeAL5iNXzqONKpM6EcYp1qnYzSblV044PuyCwy0DuGuvr9lg/3GdlCKFf2OfX96FbnQWbtjjEk+SeJjrFcd+FNwxdW/ttTYRqqctnye09tUpNHJ9S18JAyW6c35xr8G259f5rJaxzqlOd/ydffTtMoWtSwd1u8LWfRDl5hCMgOWFO8B7kKYpwhS3qJ/kF2lFYf5KcAY3gFslx8TP7bWeHSnDZVw92Vgqf4ShbVgkuV0tcfE+16P5g+MffeMuh5PiE+V0ZOsFxjP0GnXbA9+wTzqtKTzG075LLGRvxLf/SCvew15z7EZ/t6wSX09oDwVPWEngGxg++rxRc9lYufSSRKjj/Cm+tKAWXrX+X3IOS/72ZYzzVBStJlEssgNcEnASnO4kfSu4JD//Kpp4mGq5LKIZ/KLlX5rIA61gbuC49koc59Ft49rwlzn8fE0CCo5uI43jwiirGlgW4j7kDcAfMen4mXXxU4ZKI9QTkS6iikCCdfKyY7rK14mvGTFYBeZ9w8OqdAqSyAvcwxZTo5kzYFhZNILkdawcWhNYheGNiubUvzZAhFbv1ln7SCKETzyKsGy+usHYzF+VgvrikxOK3ZF2TEa6YGkDXdYJnNJcmK9aTJKwbHEcWY/cgwinOcAVxjH0BvTecgw/T2gNsm6X2IFLgCKfFaN2oWFQ3dJ6OGxbrpp3S7DY2yc0mwVklZxNcnjtpWrsB66Y6QRZsK2cUnFFyby9bJcC6OsrRXmWzjiinTg9sEY5AYqaWnO6OdIslrbUKztZ/q+Bsaa1ZcCbJWbNCoJecNcIR+gFYIxwBySnbwFZhPIctKblmw8kvm1iXPasWwxfmGDXZtuotgxyBGE93oJzbDVnRhsdFUJjmAwH79HgP79PFrZwqT/9C/h349U23ytOrbXxdBsL0M9uZtOkAEwr8uRDGMz+Vi6nXN/c+EPpx/u2on3G7VxgzQ48FSU+/Pf8pFdY6//OHrzteXFxcXFxcXPwf3G7/ACQ9Pf3NPwVXAAAAAElFTkSuQmCC)](https://aws.amazon.com/pt/s3/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8268687",
   "metadata": {
    "id": "zrL_5M2d661a",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Na etapa de **ingestão**, o `AWS S3` tem a função de passivamente armazenar as mensagens captadas pelo *bot* do **Telegram** no seu formato original: JSON. Para tanto, foi criado o *bucket* \"projeto-m42-pipeline-raw\", que será vinculado a uma função Lambda na etapa a seguir.\n",
    "\n",
    "![](https://github.com/layssasantos/Projeto-Pipeline-de-Dados-do-Telegram/blob/main/Imagens/aws_s3_ingestao.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d754eb7",
   "metadata": {
    "id": "VqKVf2A0UpBb",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "- **AWS Lambda**\n",
    "\n",
    "> [![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAH0AAAB9CAMAAAC4XpwXAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAA2UExURe1xAPCMMPKVQO56EPWvcP////OdUPvbv/727/3t3/SmYPjKn++DIPzkz/nTr/a4gPfBjwAAAC037dYAAAASdFJOU///////////////////////AOK/vxIAAAAJcEhZcwAAFxEAABcRAcom8z8AAAPMSURBVGhD7ZqNcpswEIT925A4tnn/p+0eHPhAe6LCunQ61Zemo9HYWq1Ap4X20Gg0Go1Go/GfcTz5nPUzYVyuOX7pp6L4UB1Op5+KAuqfHpD/0o8FAXVX4YaZaTOInPp3uPmcupi/azOGrLqYD73ts+qHR7D5vPoR5o/ajiCvfrhfrw9tRrCh/gvmv7UdwIb6ASXnps0AttS/Qs1vqcea31QPNb+pHmp+Wx3muyjz2+pivtdmbaD+6J8vTtpv6ONSBtSXkJXgvTXAObKE2IT5qzYrc+5vFuj8qPklkCfmsUDR+XLk75qHTZIk4/PlyBk2013HewPg5rExY/OlIkkyLazSGxmxZlBYP7RpQMQivfWRJJk+vPLeADqaJIPz5cyJ2uS9AeDKE5t8SeojMTq1yXtrcbzPAYrb5EtSCRSUizZ/3ryMPR9ksPnU5oszlmSaX22GkGPNpwVPwrU2KyN6L/PcpvTGHLSwLu6nwS80T8jrNW1WRWrJyQQbOVKJefRGvMvAufoxDD6Zf1Lz6A0wL2cITK3MpzZjzENWwoM1z58hIp4svqeb2eQ3O5MXvPc9cDk/hypmB+dJEuYr50uxrje4keRvKqW3br6crY+DT7cVt4ndUTVfSgmbq7oZ3M7kRe1XeLK157PLSnKbdSPWwvpCktusmy9XVc1Kcps1U8Z5fZab5O4ftLXMy2m2ULDmMTPyyqbelU+sLwbnL+vqvcUiI9n1xtzIyzreuwMYTdYWg/+MefGZbKqVeXLl08u1C6QpvqcmSW5ztUt3Ii7JmYHB5yLHbeJ77x+03LqMPStymzVShm/dDP06fg01UgZqOrO+LPzcPL76pvkhRmvbsK5+3CZ638uXvvXFUsfkSynoZPq4GVZ7jJrHle8ej/526x/9nr2P2bOMhOq3KqP8GqN3pvxfD+YYvYRVP3SliyS3/QS7gHl4aKQ3g3nGMRwvzyf+PJ3bJ4uJ0RZmfSNGY48Uq2MbTzHawqufc4uM7FFflpQJpwSI+WRFJnao8wrmlQDpd83vUOfWnRKwDHtrytUd6/71zSTJcnVu3SkBguwFJ0wVq+MLLJjJPtBmAguAI8Xq3Hpyvlh4vhRK1SWskb2es46pdU6MLlVPD5IBZ0UU98oXqtNqOu6D3PMZJkevfKG6U1Ly1odJ02eIMvWMdW06ONMrU3di9Jb1QYbNr0hdrHfdPfnp+LoaJE+YL8w/Jeqoplf4JGw+l+LiCPJt+1vqndK5Z+iEvOKhuDUqZfwftPh79edP3oboN1e/m9NuNBqNRqPR+Mc5HH4DibAooy9pUHsAAAAASUVORK5CYII=)](https://aws.amazon.com/pt/lambda/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f214776",
   "metadata": {
    "id": "Asz0JxphUpBu",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Durante a **ingestão**, o `AWS Lambda` irá persistir ativamente as mensagens captadas pelo *bot* do **Telegram** no *bucket* que criamos no `AWS S3` (\"projeto-m42-pipeline-raw\"). Para tanto, será utlizada uma função que opera da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae83ac5",
   "metadata": {
    "id": "jmTZB8GaUpBv",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import boto3\n",
    "\n",
    "\n",
    "def lambda_handler(event: dict, context: dict) -> dict:\n",
    "\n",
    "  '''\n",
    "  Recebe uma mensagem do Telegram via AWS API Gateway, verifica no\n",
    "  seu conteúdo se foi produzida em um determinado grupo e a escreve,\n",
    "  em seu formato original JSON, em um bucket do AWS S3.\n",
    "  '''\n",
    "\n",
    "  # vars de ambiente\n",
    "\n",
    "  BUCKET = os.environ['AWS_S3_BUCKET']\n",
    "  TELEGRAM_CHAT_ID = int(os.environ['TELEGRAM_CHAT_ID'])\n",
    "\n",
    "  # vars lógicas\n",
    "\n",
    "  tzinfo = timezone(offset=timedelta(hours=-3))\n",
    "  date = datetime.now(tzinfo).strftime('%Y-%m-%d')\n",
    "  timestamp = datetime.now(tzinfo).strftime('%Y%m%d%H%M%S%f')\n",
    "\n",
    "  filename = f'{timestamp}.json'\n",
    "\n",
    "  # código principal\n",
    "\n",
    "  client = boto3.client('s3')\n",
    "\n",
    "  try:\n",
    "\n",
    "    message = json.loads(event[\"body\"])\n",
    "    chat_id = message[\"message\"][\"chat\"][\"id\"]\n",
    "\n",
    "    if chat_id == TELEGRAM_CHAT_ID:\n",
    "\n",
    "      with open(f\"/tmp/{filename}\", mode='w', encoding='utf8') as fp:\n",
    "        json.dump(message, fp)\n",
    "\n",
    "      client.upload_file(f'/tmp/{filename}', BUCKET, f'telegram/context_date={date}/{filename}')\n",
    "\n",
    "  except Exception as exc:\n",
    "      logging.error(msg=exc)\n",
    "      return dict(statusCode=\"500\")\n",
    "\n",
    "  else:\n",
    "      return dict(statusCode=\"200\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74118194",
   "metadata": {
    "id": "YHmRyNlNUpBw",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Como estamos trabalhando com informações potencialmente sensíveis, o código foi pensado para exigir a configuração de duas variáveis de ambiente: `AWS_S3_BUCKET` com o nome do *bucket* do `AWS S3` e `TELEGRAM_CHAT_ID` com o id do *chat* do grupo do **Telegram**. Além disso, foi adicionada a permissão de escrita no *bucket* do `AWS S3` para a função do `AWS Lambda` no `AWS IAM`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775d6202",
   "metadata": {
    "id": "mbLXZuaHQ_YI",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### **4.2\\. ETL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ed2891",
   "metadata": {
    "id": "RO5ewoGuZcWq",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "A etapa de **extração, transformação e carregamento** (do inglês *extraction, transformation and load* ou **ETL**) é uma etapa abrangente responsável pela manipulação dos dados ingeridos de sistemas transacionais, ou seja, já persistidos em camadas cruas ou *raw* de sistemas analíticos. Em geral, o dado cru ingerido passa por um processo recorrente de *data wrangling* onde o dado é limpo, deduplicado, etc. e persistido com técnicas de particionamento, orientação a coluna e compressão. Por fim, o dado processado está pronto para ser analisado por profissionais de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1c4aa9",
   "metadata": {
    "id": "2Ox-j0vkX1Rd",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Neste projeto, as mensagens de um único dia, persistidas na camada cru, serão compactas em um único arquivo, orientado a coluna e comprimido, que será persistido em uma camada enriquecida. Além disso, durante este processo, o dado também passará por etapas de *data wrangling*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea00a30",
   "metadata": {
    "id": "MGzZqlFvZmN8",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Para isso, vamos utilizar uma função do `AWS Lambda` como motor de processamento e um *bucket* do `AWS S3` como camada enriquecida para a persistência do dado processado. Para garantir a recorrência, vamos configurar uma regra do `AWS Event Bridge` como gatilho diáro da função."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271fd74e",
   "metadata": {
    "id": "ygw4BAA997FY",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "- **AWS S3**\n",
    "\n",
    "> [![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAH0AAAB9CAMAAAC4XpwXAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAA2UExURXqhFoKnJYutM5OzQqS+X7TKfMXWmd7nxebt0+7z4vf58P///9Xits3cqLzQiqzEbZu5UAAAAHp0R3IAAAASdFJOU///////////////////////AOK/vxIAAAAJcEhZcwAAFxEAABcRAcom8z8AAARXSURBVGhD7ZrrtqMgDIWLeMMq8v5POzsYqq1tNUnPr/GbWWdRVyFcskmg3i4uLi4uLi4u/nucqzxTOX725zhfN20XwnB/Zui7Ns7p7/rh6tjtrO7o2sZzhZ/h6jZw8yvDAn/a0sXf9cDFzZCHfmyb2Xu3nWT4QF3Hqdv2sP1FB5x/mB6m6Ct+/Ik0tx1//T60RjdwsbQ0zkeGV1IsPejOV9rh2mXYfZQ30nAHRq19n5dxmLT1m8UNWv4owrXZdsMfVaQ8d728+27Mtq3bR6LxD2L3p5F3v9i6yG8HYUM16lgFw3g0NXH5JBO8lYtmZgyeiyfBxJv8bUuFwXPxJFitwEUzaKvn4kkSOR2XjdSQnXAVyVXu/Q/cbtk2hDuOozp2t0eMyu3U/PksJbC1ljgRS8iVWke9aakbFDEGuNTlEQwN/khbwHLFEicwA7NoCZwvCckQHbkQPz8NrJOj1muuMMb6RBecb9q+LFuIeAL5iNXzqONKpM6EcYp1qnYzSblV044PuyCwy0DuGuvr9lg/3GdlCKFf2OfX96FbnQWbtjjEk+SeJjrFcd+FNwxdW/ttTYRqqctnye09tUpNHJ9S18JAyW6c35xr8G259f5rJaxzqlOd/ydffTtMoWtSwd1u8LWfRDl5hCMgOWFO8B7kKYpwhS3qJ/kF2lFYf5KcAY3gFslx8TP7bWeHSnDZVw92Vgqf4ShbVgkuV0tcfE+16P5g+MffeMuh5PiE+V0ZOsFxjP0GnXbA9+wTzqtKTzG075LLGRvxLf/SCvew15z7EZ/t6wSX09oDwVPWEngGxg++rxRc9lYufSSRKjj/Cm+tKAWXrX+X3IOS/72ZYzzVBStJlEssgNcEnASnO4kfSu4JD//Kpp4mGq5LKIZ/KLlX5rIA61gbuC49koc59Ft49rwlzn8fE0CCo5uI43jwiirGlgW4j7kDcAfMen4mXXxU4ZKI9QTkS6iikCCdfKyY7rK14mvGTFYBeZ9w8OqdAqSyAvcwxZTo5kzYFhZNILkdawcWhNYheGNiubUvzZAhFbv1ln7SCKETzyKsGy+usHYzF+VgvrikxOK3ZF2TEa6YGkDXdYJnNJcmK9aTJKwbHEcWY/cgwinOcAVxjH0BvTecgw/T2gNsm6X2IFLgCKfFaN2oWFQ3dJ6OGxbrpp3S7DY2yc0mwVklZxNcnjtpWrsB66Y6QRZsK2cUnFFyby9bJcC6OsrRXmWzjiinTg9sEY5AYqaWnO6OdIslrbUKztZ/q+Bsaa1ZcCbJWbNCoJecNcIR+gFYIxwBySnbwFZhPIctKblmw8kvm1iXPasWwxfmGDXZtuotgxyBGE93oJzbDVnRhsdFUJjmAwH79HgP79PFrZwqT/9C/h349U23ytOrbXxdBsL0M9uZtOkAEwr8uRDGMz+Vi6nXN/c+EPpx/u2on3G7VxgzQ48FSU+/Pf8pFdY6//OHrzteXFxcXFxcXPwf3G7/ACQ9Pf3NPwVXAAAAAElFTkSuQmCC)](https://aws.amazon.com/pt/s3/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414e627c",
   "metadata": {
    "id": "FDbaRTy07G-o",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Na etapa de **ETL**, o `AWS S3` tem a função de passivamente armazenar as mensagens processadas de um dia em um único arquivo no formato Parquet. Para tanto, foi criado o *bucket* \"projeto-m42-pipeline-enriched\", que será vinculado à uma função na etapa a seguir.\n",
    "\n",
    "![](https://github.com/layssasantos/Projeto-Pipeline-de-Dados-do-Telegram/blob/main/Imagens/aws_s3_ETL.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c8b623",
   "metadata": {
    "id": "XEFJTTUQ-AcP",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "- **AWS Lambda**\n",
    "\n",
    "> [![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAH0AAAB9CAMAAAC4XpwXAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAA2UExURe1xAPCMMPKVQO56EPWvcP////OdUPvbv/727/3t3/SmYPjKn++DIPzkz/nTr/a4gPfBjwAAAC037dYAAAASdFJOU///////////////////////AOK/vxIAAAAJcEhZcwAAFxEAABcRAcom8z8AAAPMSURBVGhD7ZqNcpswEIT925A4tnn/p+0eHPhAe6LCunQ61Zemo9HYWq1Ap4X20Gg0Go1Go/GfcTz5nPUzYVyuOX7pp6L4UB1Op5+KAuqfHpD/0o8FAXVX4YaZaTOInPp3uPmcupi/azOGrLqYD73ts+qHR7D5vPoR5o/ajiCvfrhfrw9tRrCh/gvmv7UdwIb6ASXnps0AttS/Qs1vqcea31QPNb+pHmp+Wx3muyjz2+pivtdmbaD+6J8vTtpv6ONSBtSXkJXgvTXAObKE2IT5qzYrc+5vFuj8qPklkCfmsUDR+XLk75qHTZIk4/PlyBk2013HewPg5rExY/OlIkkyLazSGxmxZlBYP7RpQMQivfWRJJk+vPLeADqaJIPz5cyJ2uS9AeDKE5t8SeojMTq1yXtrcbzPAYrb5EtSCRSUizZ/3ryMPR9ksPnU5oszlmSaX22GkGPNpwVPwrU2KyN6L/PcpvTGHLSwLu6nwS80T8jrNW1WRWrJyQQbOVKJefRGvMvAufoxDD6Zf1Lz6A0wL2cITK3MpzZjzENWwoM1z58hIp4svqeb2eQ3O5MXvPc9cDk/hypmB+dJEuYr50uxrje4keRvKqW3br6crY+DT7cVt4ndUTVfSgmbq7oZ3M7kRe1XeLK157PLSnKbdSPWwvpCktusmy9XVc1Kcps1U8Z5fZab5O4ftLXMy2m2ULDmMTPyyqbelU+sLwbnL+vqvcUiI9n1xtzIyzreuwMYTdYWg/+MefGZbKqVeXLl08u1C6QpvqcmSW5ztUt3Ii7JmYHB5yLHbeJ77x+03LqMPStymzVShm/dDP06fg01UgZqOrO+LPzcPL76pvkhRmvbsK5+3CZ638uXvvXFUsfkSynoZPq4GVZ7jJrHle8ej/526x/9nr2P2bOMhOq3KqP8GqN3pvxfD+YYvYRVP3SliyS3/QS7gHl4aKQ3g3nGMRwvzyf+PJ3bJ4uJ0RZmfSNGY48Uq2MbTzHawqufc4uM7FFflpQJpwSI+WRFJnao8wrmlQDpd83vUOfWnRKwDHtrytUd6/71zSTJcnVu3SkBguwFJ0wVq+MLLJjJPtBmAguAI8Xq3Hpyvlh4vhRK1SWskb2es46pdU6MLlVPD5IBZ0UU98oXqtNqOu6D3PMZJkevfKG6U1Ly1odJ02eIMvWMdW06ONMrU3di9Jb1QYbNr0hdrHfdPfnp+LoaJE+YL8w/Jeqoplf4JGw+l+LiCPJt+1vqndK5Z+iEvOKhuDUqZfwftPh79edP3oboN1e/m9NuNBqNRqPR+Mc5HH4DibAooy9pUHsAAAAASUVORK5CYII=)](https://aws.amazon.com/pt/lambda/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08309a2",
   "metadata": {
    "id": "LkeS09KecK4q",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "A função do `AWS Lambda`, no momento de ETL, é de ativamente processar as mensagens captadas pelo *bot* do **Telegram**, persistidas na camada cru no *bucket* do `AWS S3` (criado na etapa de ingestão), e persisti-las na camada enriquecida, também em um *bucket* do `AWS S3`(o qual acabamos de criar na etapa de ETL). Logo, será utilizada uma função que opera da seguinte forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ef55cb",
   "metadata": {
    "id": "LNOS0msDQwfg",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "O código da função:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b44312",
   "metadata": {
    "id": "T6EBaPdDKlGj",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "import boto3\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "\n",
    "def lambda_handler(event: dict, context: dict) -> bool:\n",
    "\n",
    "  '''\n",
    "  Diariamente é executado para compactar as diversas mensagensm, no formato\n",
    "  JSON, do dia anterior, armazenadas no bucket de dados cru, em um único\n",
    "  arquivo no formato PARQUET, armazenando-o no bucket de dados enriquecidos\n",
    "  '''\n",
    "\n",
    "  # vars de ambiente\n",
    "\n",
    "  RAW_BUCKET = os.environ['AWS_S3_BUCKET']\n",
    "  ENRICHED_BUCKET = os.environ['AWS_S3_ENRICHED']\n",
    "\n",
    "  # vars lógicas\n",
    "\n",
    "  tzinfo = timezone(offset=timedelta(hours=-3))\n",
    "  date = (datetime.now(tzinfo) - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "  timestamp = datetime.now(tzinfo).strftime('%Y%m%d%H%M%S%f')\n",
    "\n",
    "  # código principal\n",
    "\n",
    "  table = None\n",
    "  client = boto3.client('s3')\n",
    "\n",
    "  try:\n",
    "\n",
    "      response = client.list_objects_v2(Bucket=RAW_BUCKET, Prefix=f'telegram/context_date={date}')\n",
    "\n",
    "      for content in response['Contents']:\n",
    "\n",
    "        key = content['Key']\n",
    "        client.download_file(RAW_BUCKET, key, f\"/tmp/{key.split('/')[-1]}\")\n",
    "\n",
    "        with open(f\"/tmp/{key.split('/')[-1]}\", mode='r', encoding='utf8') as fp:\n",
    "\n",
    "          data = json.load(fp)\n",
    "          data = data[\"message\"]\n",
    "\n",
    "        parsed_data = parse_data(data=data)\n",
    "        iter_table = pa.Table.from_pydict(mapping=parsed_data)\n",
    "\n",
    "        if table:\n",
    "\n",
    "          table = pa.concat_tables([table, iter_table])\n",
    "\n",
    "        else:\n",
    "\n",
    "          table = iter_table\n",
    "          iter_table = None\n",
    "\n",
    "      pq.write_table(table=table, where=f'/tmp/{timestamp}.parquet')\n",
    "      client.upload_file(f\"/tmp/{timestamp}.parquet\", ENRICHED_BUCKET, f\"telegram/context_date={date}/{timestamp}.parquet\")\n",
    "\n",
    "      return True\n",
    "\n",
    "  except Exception as exc:\n",
    "      logging.error(msg=exc)\n",
    "      return False\n",
    "\n",
    "# código da função de Data Wrangling\n",
    "\n",
    "def parse_data(data: dict) -> dict:\n",
    "\n",
    "  date = datetime.now().strftime('%Y-%m-%d')\n",
    "  timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "  parsed_data = dict()\n",
    "\n",
    "  for key, value in data.items():\n",
    "\n",
    "      if key == 'from':\n",
    "          for k, v in data[key].items():\n",
    "              if k in ['id', 'is_bot', 'first_name']:\n",
    "                parsed_data[f\"{key if key == 'chat' else 'user'}_{k}\"] = [v]\n",
    "\n",
    "      elif key == 'chat':\n",
    "          for k, v in data[key].items():\n",
    "              if k in ['id', 'type']:\n",
    "                parsed_data[f\"{key if key == 'chat' else 'user'}_{k}\"] = [v]\n",
    "\n",
    "      elif key in ['message_id', 'date', 'text']:\n",
    "          parsed_data[key] = [value]\n",
    "\n",
    "  if not 'text' in parsed_data.keys():\n",
    "    parsed_data['text'] = [None]\n",
    "\n",
    "  return parsed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cbaf9b",
   "metadata": {
    "id": "oHGo7VLXZMDH",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Aqui também fizemos algumas configurações no AWS Lambda. Já que o código exige a configuração de duas variáveis de ambiente: AWS_S3_BUCKET e AWS_S3_ENRICHED com os nomes dos bucket do AWS S3 da camada cru e enriquecida, respectivamente. Além disso, foi adicionada a permissão de escrita nos buckets do AWS S3 para a função do AWS Lambda no AWS IAM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b70913",
   "metadata": {
    "id": "PvispzZRQy40",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "- **AWS Event Bridge**\n",
    "\n",
    "> [![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAH0AAAB9CAMAAAC4XpwXAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAA2UExURecVe+kkg+tBlOoyi/OKvfvT5v3w9/////WZxe1PnPzi7/BtrPnF3vF7te9epPanzfe21gAAAD55YsoAAAASdFJOU///////////////////////AOK/vxIAAAAJcEhZcwAAFxEAABcRAcom8z8AAATxSURBVGhD7ZrpspswDIUDJCxZLvf9n7bnYAEGJGMTD51O+dofbgg22o5EpreLi4uLi4uLi/+SoiwrWZ5NcX/WTdPU7d94gPKJox13+eg8XsO5NB685cOzqHBufafPP/RB6z49iwcO/5H1G8cXsj6FHxzYyfpWwPpe1qcAc71YMwdkeQqwdjIdIAlKWZJ7u+GeMzQ4zt8OWfCSJZFKWFDLtRysjEUgxhQk2umLx/sSeN7fbRWIredZInIxA+0i6zqYthNXfCNfWbDiJtcXcPze1h/ckK8fUGFkt6L3H8UCwcmnxyVObFq6+wf7Rigto+PnxncMx4/0EdUMbyHxiipP4XsdNqqaCnyvf7AY31l60gt1BIPwFHWMQUyPkTzFX5alM0r+HcJNBEK+gYTb7lfTMBH0CHvF6ssofVHVxKyTpC8ofXmyDzD/96qJFTfZm3ci+MXWsrTAV35lCRCsfLrPxNvJI0Tdcw9vyOb62313N3zBz0xEPp/yMfE8xyqsYoPv+xNBNIVaK0yq3xW933pW88hRz/82T6WhVdhui1wkyy4cMRGoLCpnxpfRGe88StL81EcrTr+PFd++Pos/fCDPPtw4KUzURKAAlRwVywd+3aodQr0av5zXOjzIsXcv7Kjcx523tvBT70ldl6k5FR30O+pa0yg8k1Zv0Df/24P1jkNDFvuUomnUGi2MVLRFhra433Ek6vDaU5YexjMBZNeqlxVdVzEBlW32sKvNahl2haTrrL2Xqn/AGDwieuIGtkUlXgiHLfEIipZhOD11tsItSrXRPNuNhpNZO2lKi3c3zV2wLlS8hpMRxHBPXGGEd9cK/TYjIUwQXiWzC7PaRqjpyjkYLxKqThfTULWN6KEJVcoWHPOQpQ/22EteQ52DpbLGsH0l5Rq67YZyWSBLtbjvbkLTlbjD9JRWY5yzlfIlRhOg6UliaySYLr8T9l1J9R7SOrtfMrWV0RnKpYl2CLZxWfrAtXYEjfDuqoSC7i5DygcMx6BS0ht8etXBRiVYaUozQbUt7++6efb+3eZmeaptxH9j8QZrdj+tZRjVFu7JAVA/M7O9OEWrOqPa8O3EahOQd837VVbd8BiTAfzhdGs800SpNoYjsdocNEYsplfnFyX0y20P0sNrT8A7MFc/sl66m1fazwtvb/NfZoNmY1tbFRIGPvOMQfLM23CAUtBy8VYe8jutXRXavLs7bc2RwrJAzvmPjWDPD9PJDxY+OP5QZenAdv90ZJUuMiMRo0cCK9vxMDumwfhD6a2CgvNEhcKnZtUMu2LaS0MAZvl8Hvy6m1RwzzFZ04Drp84YpdbJA1QIbubErqLURpjFrijL76F+4dQ3ii1uQGByhAsjBeaREKckbA3IlTJP8g0uHwhNsh5IvMfgqvehH2Y3dOgh9EGcXLP7Co9jAq8Ak+Jc71IFXye58j80yfqwMOsXjC6HkOWynj1ElgH4/jXOHSUckK38sO9+LXGMkqXzV57Um2opDMz1HhG3ZBNeJt59g1x0QGx8X0Mrs7meCbVFLjpw3GLaXF//hkFE1sg1x8pY6q4sv6do+y1yzVE1iwEWynPg5+HjIDe8LIfy5Gv3EbAwZOkKPlu3j4FqMypyVrWJgzL/GJyPd5iTTQeuIw//BTPnoBGLa3JkfAM9FRlI6nyjfSJVd/DV8eLi4uLi4uLiX+Z2+wNo3TOPquwQ+AAAAABJRU5ErkJggg==)](https://aws.amazon.com/pt/eventbridge/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab43bcf2",
   "metadata": {
    "id": "T3bN2m7m7UYr",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Na etapa de **ETL**, o `AWS Event Bridge` tem a função de ativar diariamente a função de **ETL** do `AWS Lambda`, funcionando assim como um *scheduler*, ou seja, ele é responsável por inicializar o processo de transformação, uma vez ao dia às 00:00h.\n",
    "\n",
    "![](https://github.com/layssasantos/Projeto-Pipeline-de-Dados-do-Telegram/blob/main/Imagens/aws_eventbridge_rule.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0556277c",
   "metadata": {
    "id": "H68Afxuoazbb",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### 4.3. **Apresentação**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75896b9",
   "metadata": {
    "id": "2Z6XphlWQ40B",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "A etapa de **apresentação** é reponsável por entregar o dado para os usuários (analistas, cientistas, etc.) e sistemas (dashboards, motores de consultas, etc.), idealmente através de uma interface de fácil uso, como o SQL, logo, essa é a única etapa que a maioria dos usuários terá acesso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466a6160",
   "metadata": {
    "id": "WN1tLjfUQ40B",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "- **AWS Athena**\n",
    "\n",
    "> [![image.png](data:image/png;base64,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)](https://aws.amazon.com/pt/athena/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d47aff",
   "metadata": {
    "id": "ws97sO4LQ40B",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Neste momento, o `AWS Athena` tem a função de entregar o dados através de uma interface SQL para os usuários do sistema analítico. Para criar a interface, foi criada uma tabela externa sobre o dado armazenado na camada mais refinada da arquitetura, a camada enriquecida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b2a751",
   "metadata": {
    "id": "hjsrFaxafJnB",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    ">**Query**:\n",
    "```sql\n",
    "CREATE EXTERNAL TABLE `telegram`(\n",
    "  `message_id` bigint,\n",
    "  `user_id` bigint,\n",
    "  `user_is_bot` boolean,\n",
    "  `user_first_name` string,\n",
    "  `chat_id` bigint,\n",
    "  `chat_type` string,\n",
    "  `text` string,\n",
    "  `date` bigint)\n",
    "PARTITIONED BY (\n",
    "  `context_date` date)\n",
    "ROW FORMAT SERDE\n",
    "  'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
    "STORED AS INPUTFORMAT\n",
    "  'org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat'\n",
    "OUTPUTFORMAT\n",
    "  'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat'\n",
    "LOCATION\n",
    "  's3://<bucket-enriquecido>/'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae509962",
   "metadata": {
    "id": "L_XiPFyOOxze",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Por fim, foram adicionadas as partições**\n",
    ">**Query**:\n",
    "```sql\n",
    "MSCK REPAIR TABLE `telegram`;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3a24e7",
   "metadata": {
    "id": "krcRJ4OcO6tX",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Consultando as 10 primeiras linhas para observar o resultado**\n",
    "\n",
    ">**Query**:\n",
    "```sql\n",
    "SELECT * FROM `telegram` LIMIT 10;\n",
    "```\n",
    "\n",
    "![](https://github.com/layssasantos/Projeto-Pipeline-de-Dados-do-Telegram/blob/main/Imagens/table_10.JPG?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d3f3c0",
   "metadata": {
    "id": "y0GAuhJxQ40B",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "- **Analytics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a85a33",
   "metadata": {
    "id": "jzA596vHkrnj",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Com o dado disponível, podemos executar as mais variadas consultas analíticas. Seguem alguns exemplos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40273d60",
   "metadata": {
    "id": "H5jg8V2NkuLn",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Quantidade de mensagens por dia**\n",
    "\n",
    ">**Query**:\n",
    "```sql\n",
    "SELECT\n",
    "  context_date,\n",
    "  count(1) AS \"message_amount\"\n",
    "FROM \"telegram\"\n",
    "GROUP BY context_date\n",
    "ORDER BY context_date DESC\n",
    "```\n",
    "\n",
    "![](https://github.com/layssasantos/Projeto-Pipeline-de-Dados-do-Telegram/blob/main/Imagens/amount_day.JPG?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a6dc1a",
   "metadata": {
    "id": "yFKFbHqulCDP",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Quantidade de mensagens por usuário por dia**\n",
    "\n",
    ">**Query**:\n",
    "```sql\n",
    "SELECT\n",
    "  user_id,\n",
    "  user_first_name,\n",
    "  context_date,\n",
    "  count(1) AS \"message_amount\"\n",
    "FROM \"telegram\"\n",
    "GROUP BY\n",
    "  user_id,\n",
    "  user_first_name,\n",
    "  context_date\n",
    "ORDER BY context_date DESC\n",
    "```\n",
    "\n",
    "![](https://github.com/layssasantos/Projeto-Pipeline-de-Dados-do-Telegram/blob/main/Imagens/amount_user_day.JPG?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e78f54",
   "metadata": {
    "id": "0oZjoNkPlSHd",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Média do tamanho das mensagens por usuário por dia**\n",
    ">**Query**:\n",
    "```sql\n",
    "SELECT\n",
    "  user_id,\n",
    "  user_first_name,\n",
    "  context_date,\n",
    "  CAST(AVG(length(text)) AS INT) AS \"average_message_length\"\n",
    "FROM \"telegram\"\n",
    "GROUP BY\n",
    "  user_id,\n",
    "  user_first_name,\n",
    "  context_date\n",
    "ORDER BY context_date DESC\n",
    "```\n",
    "\n",
    "![](https://github.com/layssasantos/Projeto-Pipeline-de-Dados-do-Telegram/blob/main/Imagens/average_msg.JPG?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a31902",
   "metadata": {
    "id": "7SJckV-nTpQ_",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Quantidade de mensagens por hora por dia da semana por número da semana**\n",
    ">**Query**:\n",
    "```sql\n",
    "WITH\n",
    "parsed_date_cte AS (\n",
    "    SELECT\n",
    "        *,\n",
    "        CAST(date_format(from_unixtime(\"date\"),'%Y-%m-%d %H:%i:%s') AS timestamp) AS parsed_date\n",
    "    FROM \"telegram\"\n",
    "),\n",
    "hour_week_cte AS (\n",
    "    SELECT\n",
    "        *,\n",
    "        EXTRACT(hour FROM parsed_date) AS parsed_date_hour,\n",
    "        EXTRACT(dow FROM parsed_date) AS parsed_date_weekday,\n",
    "        EXTRACT(week FROM parsed_date) AS parsed_date_weeknum\n",
    "    FROM parsed_date_cte\n",
    ")\n",
    "SELECT\n",
    "    parsed_date_hour,\n",
    "    parsed_date_weekday,\n",
    "    parsed_date_weeknum,\n",
    "    count(1) AS \"message_amount\"\n",
    "FROM hour_week_cte\n",
    "GROUP BY\n",
    "    parsed_date_hour,\n",
    "    parsed_date_weekday,\n",
    "    parsed_date_weeknum\n",
    "ORDER BY\n",
    "    parsed_date_weeknum,\n",
    "    parsed_date_weekday\n",
    "```\n",
    "\n",
    "![](https://github.com/layssasantos/Projeto-Pipeline-de-Dados-do-Telegram/blob/main/Imagens/hour_day_week.JPG?raw=true)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7.255886,
   "end_time": "2024-01-22T18:54:40.801201",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-22T18:54:33.545315",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
